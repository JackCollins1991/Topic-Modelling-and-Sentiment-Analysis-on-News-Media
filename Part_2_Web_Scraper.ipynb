{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jack_Collins_MA5851_A3_Part1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "I1ufnk--ahT0",
        "4ZV3MugkZGs8",
        "Qj_Zr_ciLQ9Q",
        "c_B-5Je7v1VF",
        "a3sbGiBQgn5E"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-nEWxgR5o9M"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx4U9Zsw8kna"
      },
      "source": [
        "This notebook explains a pipeline for:     \n",
        "* Taking a URL as input\n",
        "* Extracting all URLs found on that page which match specified criteria\n",
        "* Extracting the text on each of those sub-URLS\n",
        "* Generating a data table of the url, the text and the first title located on that page\n",
        "* Writing this data to a CSV, which is expected to then be used in a subsequent pipeline. \n",
        "\n",
        "This is the abstract task which this pipeline accomplishes. In this scenario, we will configure the pipeline for a specific use case, which is:    \n",
        "* Input the URL for 'The Daily Mail Australia' news publication\n",
        "* Extract every news article on the front page of the website\n",
        "* Extract all text from each article, which will then be used in 'Part 3 NLP Analysis' notebook.\n",
        "\n",
        "## Extending and Scaling this Prototype\n",
        "This pipeline contains fucntions and a template for a pipeline which can be sued to accomplish this abstracted use case. This is intended as a prototype which could later be developed into:    \n",
        "* An application for extarcting text from all, or a query-filteres subset of, news articles on a news website. This would require altering the current method which only evaluates URLs from the inputted webpage. This new implementation would extract every URL present on the domain which meets a specified criteria. \n",
        "* This example will collected around 100-200 articles and takes aproximatley 2.5 minutes to run. The majority of computation time is from extracting text from the larger HTML text blobs. To scale the application to many thousands or millions of artciles, could be accomplished by distributing out the processing for each sub-URL across parallel computers. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X6RuZ8zBwrD"
      },
      "source": [
        "## Describing the Web Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaVY7lcDbd7k"
      },
      "source": [
        "a. Websites to be consumed \n",
        "\n",
        "b. A rationale for extracting the web content \n",
        "\n",
        "c. Content coverage of the data extracted \n",
        "\n",
        "d. Complexity of the content layout \n",
        "\n",
        "e. Website/data copyright considerations \n",
        "\n",
        "f. Metadata supplementation and rational for the supplementation \n",
        "\n",
        "g. Content extractor to export the important aspects of the data and/or metadata \n",
        "\n",
        "h. Relevant python coding \n",
        "\n",
        "i. Demonstration of the application of the WebCrawler (i.e. screen shots) \n",
        "\n",
        "j. Methodology of processing, cleaning, and storing harvested data for NLP \n",
        "tasking \n",
        "\n",
        "k. Summary and visualisation of the harvested data. Preliminary EDA is \n",
        "acceptable in this section as well. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsL5839WZDuh"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd-mK_jbI4Pq"
      },
      "source": [
        "In the following section, we:      \n",
        "* Import required modules\n",
        "* Set the configratuin constants, inluding the target URLs. This pipeline should be capable of performing the same task for different use cases by changing only the configrations. No changes to the code are required. \n",
        "* Define thefunctons for use in the 'Execution' section.\n",
        "* Connect this runtime to filestorage (Google Drive) to store the output file. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1ufnk--ahT0"
      },
      "source": [
        "## Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea7sAKQeZSbL"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from pprint import pprint\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3B0FUMbaklt"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTHjLFjUL4iv"
      },
      "source": [
        "The constants are the runtime variables which can be set here in this one code chunk. Future versions of this application could set these variables from an external config file. By changing the constants here, this pipeline can accomplish its task on a different use case, without any need to change code. \n",
        "These constants are:     \n",
        "\n",
        "* MAIN_URL - This is the inputted webpage from which we will extract the URLS found there. An example would be the home page of a news website. \n",
        "* DOMAIN - URLs on pages are often partial urls and we will append this domain to the start to create the full URL. \n",
        "* SCRAPE_OUTPUT_FILE - File location for the output file. \n",
        "* ARTICLE_TAG = - the html tag we can use to identify when an element contains the a URL we are interested in. For example 'a' tags contain articles, while other tags may contain URLS to ad sites. \n",
        "* URL_HTML_TAG - Th etag which indicates the URL, this is commonly 'href'\n",
        "* URLS_START_WITH - Filters in only URLS that start with this substring. \n",
        "* URLS_NOT_END_WITH - FIlters out URLs that end with the substring. \n",
        "* TEXT_TAG - The HTML tag which indicates the body text we want to extract. \n",
        "* REMOVE_SUBSTRINGS List of characters and substrings which can be cleaned out of the extracted text. \n",
        "* SEED - The random seed to be set for reproduceability. \n",
        "\n",
        "The HTML tags and URL substrings to filter with are determined by examining the HTML for the target pages directly. This will be demonstrated in the 'Execution' section below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__m-1cnjY94B"
      },
      "source": [
        "MAIN_URL = 'https://www.dailymail.co.uk/news/breaking_news/index.html'\n",
        "DOMAIN = 'https://www.dailymail.co.uk'\n",
        "SCRAPE_OUTPUT_FILE = '/content/drive/MyDrive/MA5851_A3/scrape_results.csv'\n",
        "ARTICLE_TAG = 'a'\n",
        "URL_HTML_TAG = 'href'\n",
        "URLS_START_WITH = ['https://www.dailymail.co.uk']\n",
        "URLS_NOT_END_WITH = ['#video']\n",
        "TEXT_TAG = 'p'\n",
        "REMOVE_SUBSTRINGS = [\"]\",'\"',\"'\",\".\",\",\",\"[\",\"/\",\">\",\"<\"]\n",
        "SEED = 42"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPqxXpP8mJJ5"
      },
      "source": [
        "## File Storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8TwB-0LmFQe",
        "outputId": "d1dd4932-2fd0-45ce-e30a-38202d5d7f6d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZV3MugkZGs8"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjOYu0SeTCG0"
      },
      "source": [
        "Where the imported module's fiuunctionality isn't precisley suited for our use cases, it is appropriate to define some custome functions. These functions are re-useable for other use cases. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILtxJO7JeW5m"
      },
      "source": [
        "### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPVJ0UnueZgd"
      },
      "source": [
        "def Set_All_Seeds(seed):\n",
        "  \"\"\"Aims to set all used random seeds in one place.\"\"\"\n",
        "  random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  np.random.seed(seed)\n",
        "  np.random.RandomState(seed)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj_Zr_ciLQ9Q"
      },
      "source": [
        "### HTML Element Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC7xdREIenUG"
      },
      "source": [
        "def Get_Soup(url: str):\n",
        "  \"\"\"Input a url and return the BeautifulSoup instance (aka: a 'soup').\"\"\"\n",
        "  data = requests.get(url)\n",
        "  html = BeautifulSoup(data.text, 'html.parser')\n",
        "  return html"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z5nv78ojRcZ"
      },
      "source": [
        "def Get_Links(soup: BeautifulSoup, find_tag: str, get_tag: str):\n",
        "  \"\"\"Extracts every URL found in the 'get_tag' of each 'find_tag' in the soup.\"\"\" \n",
        "  results = []\n",
        "  for link in soup.find_all(find_tag):\n",
        "    results.append(link.get(get_tag))\n",
        "  return results"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Neki7NkjR7Bs"
      },
      "source": [
        "def Get_Content(soup: BeautifulSoup, tag: str):\n",
        "  \"\"\"Input a soup, return a list of strings which are the \n",
        "  contents found between each tag\"\"\"\n",
        "  results = []\n",
        "  for p in soup.find_all(tag):\n",
        "    results.append(p.contents)\n",
        "  return results"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3sbGiBQgn5E"
      },
      "source": [
        "### Text Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1enatLvguPO"
      },
      "source": [
        "def Remove_Sub_Strings(string: str, remove: list):\n",
        "  \"\"\"User can input a list of substrings which will all be \n",
        "  removed from the string\"\"\"\n",
        "  for r in remove:\n",
        "    assert isinstance(string, str)\n",
        "    string = string.replace(r,\"\")\n",
        "  return string\n",
        "\n",
        "def Clean_String(s: str):\n",
        "  \"\"\"Cleans regex characters from string\"\"\"\n",
        "  s = re.compile(r'<[^>]+>')\n",
        "  return re.sub('(^|\\s+)FIRST($|\\s+)', '', s)\n",
        "\n",
        "def Get_Text_From_Page(url: str):\n",
        "  \"\"\"Input a url and returns only the text found on the page.\n",
        "  Reuires runtime variable 'TEXT_TAG' and 'REMOVE_SUBSTRINGS' to be defined.\"\"\"\n",
        "  web_text = Get_Content(soup = Get_Soup(url), tag=TEXT_TAG)\n",
        "  return Remove_Sub_Strings(str(web_text), remove = REMOVE_SUBSTRINGS)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_B-5Je7v1VF"
      },
      "source": [
        "### Link Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnwGCEtYolD2"
      },
      "source": [
        "def Select_Links_Starts_With(links: list, stem: str):\n",
        "  \"\"\"Input a list of URLS, returns the URLs which start with the stem\"\"\"\n",
        "  results = []\n",
        "  for link in links:\n",
        "    if not isinstance(link, str):\n",
        "      continue\n",
        "    if link.startswith(stem):\n",
        "      results.append(link)\n",
        "  return results\n",
        "\n",
        "def Select_Links_Ends_With(links: list, stem: str):\n",
        "  \"\"\"Input a list of URLS, returns the URLs which end with the stem\"\"\"\n",
        "  results = []\n",
        "  for link in links:\n",
        "    if not isinstance(link, str):\n",
        "      continue\n",
        "    if link.endswith(stem):\n",
        "      results.append(link)\n",
        "  return results\n",
        "\n",
        "def Remove_Links(func, links: list, stems: list):\n",
        "  \"\"\"Allows users to filter out URLs with a list of stems.\"\"\"\n",
        "  for s in stems:\n",
        "    delta = func(links = links, stem=s)\n",
        "    links = list(set(links) - set(delta))\n",
        "  return links\n",
        "\n",
        "def Append_Links(func, links: list, stems: list):\n",
        "  \"\"\"Allows users to filter in URLs with a list of stems.\"\"\"\n",
        "  results = []\n",
        "  for s in stems:\n",
        "    delta = func(links = links, stem=s)\n",
        "    results.append(delta)\n",
        "  return results[0]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spLnfetLv8r1"
      },
      "source": [
        "# Execute Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-_p1My-efV5"
      },
      "source": [
        "Set_All_Seeds(SEED)\n",
        "start_time = time.time()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVM-P8o5WxpC"
      },
      "source": [
        "## Extract webpages\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjXZ0CP44K9J"
      },
      "source": [
        "# Take the main URL and extract all desired URLs found on that webpage into a list. \n",
        "main_soup = Get_Soup(MAIN_URL)\n",
        "URLs = Get_Links(soup = main_soup, find_tag = ARTICLE_TAG, get_tag = URL_HTML_TAG)\n",
        "URLs = Append_Links(func = Select_Links_Starts_With,links = URLs, stems = URLS_START_WITH)\n",
        "URLs = Remove_Links(func = Select_Links_Ends_With,links = URLs, stems = URLS_NOT_END_WITH)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FPy6-NMYZwU"
      },
      "source": [
        "We can examine a sample of the main page HTML code here. From exploring the full HTML document, we can determine the tags and url stems needed to extract the desired URLS and set those porperties in the configuration. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "TfbKxq8OYV0u",
        "outputId": "4212b7a9-e3a0-4b69-95e0-7b55cfeb43df"
      },
      "source": [
        "str(main_soup)[0:300]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"//www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\n<html><head><script type=\"text/javascript\">\\ntry {\\n  Object.defineProperty(window, \\'adverts\\', {configurable: false, value:{}});\\n}\\ncatch(error) {\\n  console.error(error);\\n}\\n</script><lin'"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UOSUw7aYokz"
      },
      "source": [
        "Using the tags and stems we have inputted into the configuration, we can extract a list of URLs as follows. The number of URLs extracted will be detailed in the output section below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFDtKUXeYv6J",
        "outputId": "7d91e408-6093-4670-e6da-89b2cd74d64a"
      },
      "source": [
        "URLs[0:4]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://www.dailymail.co.uk/news/article-10217729/Fired-Baltimore-cop-female-officer-accomplice-carry-SECOND-kidnapping.html#comments',\n",
              " 'https://www.dailymail.co.uk/news/article-10235429/Biden-ignores-questions-saying-families-rest-easy-shelves-full.html#comments',\n",
              " 'https://www.dailymail.co.uk/news/article-10225803/Europe-descends-chaos-second-night-protests-continue-Austria-Holland-Denmark.html#comments',\n",
              " 'https://www.dailymail.co.uk/sport/sportsnews/article-10125861/Ole-Gunnar-Solskjaer-SACKED-Manchester-United-brutal-loss-Watford.html#comments']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwyP72T-Y2yn"
      },
      "source": [
        "We can apply our custom function to extract all body text for each URL in the list. See in the below example, that some html code and unwanted sub strings are still in the text. These will be removed with stop words in the subsequent pipeline.' "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "Qr0pefA4ikcn",
        "outputId": "6bf5e6eb-8a0c-4f68-a4f4-8a1e1afa0334"
      },
      "source": [
        "Get_Text_From_Page(URLs[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'By  a class=author href=homesearchhtml?s=&amp;authornamef=Tommy+Taylor rel=nofollowTommy Taylora  and  a class=author href=homesearchhtml?s=&amp;authornamef=Ronny+Reyes+For+DailymailCom rel=nofollowRonny Reyes For DailymailComa   span class=article-timestamp article-timestamp-published span class=article-timestamp-labelPublished:span time datetime=2021-11-18T19:35:17+0000 19:35 GMT 18 November 2021 time span  |  span class=article-timestamp article-timestamp-updated span class=article-timestamp-labelUpdated:span time datetime=2021-11-19T04:50:56+0000 04:50 GMT 19 November 2021 time span     89 View  br  comments  A terminated Maryland cop his suspended police accomplice and his two daughters who he kidnapped were all found dead inside a crashed vehicle in an apparent murder-suicide after a five-day manhunt on Thursday police said\\\\xa0\\\\xa0\\\\xa0 Robert Vicosa 42 had taken his daughters Aminah 6 and Giana 7 from their Windsor Pennsylvania home on Sunday He was accompanied by\\\\xa0Sgt Tina Bynum 36 a recently suspended member of the Baltimore County Police Department\\\\xa0 Smithburg Police had been in pursuit of Vicosa and Bynum inside a stolen vehicle when it crashed in Maryland\\\\xa0 Maryland State Police spokeswoman Elena Russo said a crisis negotiation team tried to approach the car but smoke from the car made it difficult to see inside\\\\xa0\\\\xa0 Vicosa had reportedly been found dead from a self-inflicted gunshot wound and Baltimore Police confirmed that the three others were found with gunshot wounds One of the girls had been transported to a nearby hospital in Hagerstown where she was later pronounced dead\\\\xa0 A heavy police presence has been reported with helicopters and trucks surrounding the area The deaths were first reported by\\\\xa0 a class=class href=https:wwwwbaltvcomarticlerobert-vicosa-tia-bynum-cockeysville-kidnapping38289726# rel=nofollow noreferrer noopener style=font-weight: bold; target=_blank11 News I-Teama  Police are advising people to stay away from the Midvale Road and Ringgold Pikle area in Waynesboro due to the incident The investigation is currently on-going\\\\xa0 \\\\xa0  Robert Vicosa 42 (left) had allegedly carried out a second kidnapping and held the victim at gunpoint on Wednesday morning in Cockeysville Maryland with former colleague and accomplice Tia Bynum 36 (right) Vicosa had kidnapped his daughters Aaminah six and Giana Vicosa seven from their Windsor Pennsylvania home on Sunday They were reportedly last seen on Tuesday at 1149am\\\\xa0 Robert Vicosa Tina Bynum Aminah Viscosa and Giana Viscosa were all found dead inside a crashed car on Thursday afternoon after Robert sparked a five-day manhunt after kidnapping his two young daughters aged six and seven A heavy police presence has been reported with helicopters and trucks surrounding the area The crash happened outside local Bonnie Zeiglers door who told CBS that the entire neighborhood was shaken up by the event\\\\xa0 I just could not believe that theyre all gone that those dear little girls are all gone said Zeigler\\\\xa0 The five-day manhunt began after Vicosa held their mother captive at gunpoint at the home on Friday as she was tied up by her wrists and ankles Sgt Tina Bynum 36 who has now been suspended was said to be with Vicosa after they were seen on Wednesday afternoon in Cockeysville Maryland The pair Sgt Tina Bynum allegedly kidnapped a male victim at gunpoint and demanded he drive them to various areas in Baltimore County The male victim was later found to be unharmed August 2007: Vicosa failed to appear in court and accepted a written reprimand from the Baltimore County Police Department May 2008: He then again failed to appear in court and accepted a one-day loss of leave June 2019: A trial board made up of members of the police department found him guilty of allegations related to improper conduct with female subordinates The police department demoted him by two ranks March 2021: An internal investigation found he was sleeping on the job and refusing to perform his duties August 2021: His employment with the police department was terminated Source: Baltimore County Police Department\\\\xa0 The victim had told  a class=class href=https:baltimorecbslocalcom20211118vehicle-driven-by-robert-vicosa-reportedly-found-in-western-maryland rel=nofollow noreferrer noopener style=font-weight: bold; target=_blankCBS a that he was worried about the little girls in the car and felt exhausted after the ordeal was over\\\\xa0 \\\\xa0 Vicosa was charged with kidnapping assault and robbery with Bynum was also charged for false imprisonment\\\\xa0\\\\xa0\\\\xa0 Vicosa and Bynum had previously worked together at the Baltimore County Police Department before he was terminated in August for\\\\xa0sleeping on the job and insubordination Bynum who worked for the department for 14 years was suspended from her position on Tuesday as she also reportedly had a record of disciplinary problems\\\\xa0\\\\xa0 Police believe that Bynum had allegedly helped Vicosa keep his estranged wife captive at the Windsor home the weekend before the girls were kidnapped according to  a class=class href=https:wwwydrcomstorynews20211118robert-vicosas-longtime-friend-tia-bynam-charged-in-kidnapping-york-county-girls8663718002 rel=nofollow noreferrer noopener style=font-weight: bold; target=_blankYork Daily Recorda  His wife had been invited to the home for her birthday celebration with her two daughters on Friday night\\\\xa0 After the girls went to bed Vicosa enticed his wife with a present which he claimed to be a bracelet She was then grabbed by the arms by both Vicosa and Bynum and had a gun placed to her head by her husband an affidavit said The pair tied her up by the wrists and ankles after leading her into the basement According to police the restraints were untied at some point The wife had begged her husband to go back to her home on Sunday morning to get her clothes and computer after convincing him she wanted to stay\\\\xa0 She then went home to tell her mother about the assault before going to a Target in\\\\xa0Springettsbury Township to seek help the York Daily Record reported The wife reported the weekend assault on Sunday to local police where she claimed she had been forced to take drugs touch firearms and even was sexually assaulted by Vicosa\\\\xa0 Sources now say Robert Vicosa Tia Bynum and Vicosas 2 children are all dead Search for the former Baltimore County officer ended in Washington Co this afternoon after car he was using was found along the road  a href=https:tcoaRfRaZerfy rel=nofollow noreferrer noopener target=_blankpictwittercomaRfRaZerfya The girls have been featured on a missing and endangered list with their kidnapping date reported as Sunday Vicosa is believed to be driving Bynums 2013 Black Lexus G50 with Pennsylvania license plate number KPK2076 Bynum had allegedly held items for Vicosa while his wife was being held captive The wife also told the department that she believed Vicosa had tracking devices on her phone and vehicle The victims mother had also told police that she received texts from her daughter over the weekend with pictures of her granddaughters at the home on Friday night as well being told that they were staying at the home overnight She thought it was strange as she claimed her daughter was scared of Vicosa and also said that the texts did not match up to way her daughter talked\\\\xa0 The mother had been originally told by her daughter that she was going out to buy ingredients to make fudge on Friday The ingredients were still on the counter on Saturday morning and discovered that Vicosa had driven her daughter to his home after checking security footage The victims brother also said he received a text from his sister on Saturday claiming that she was okay after he found at she was at Vicosas home According to the affidavit Vicosa had threatened to kill his wife his two young daughters and himself over the weekend\\\\xa0\\\\xa0 Police obtained a warrant to search Vicosas but discovered that he and both his daughters were gone\\\\xa0 The children were been taken by Vicosa in a black Acura that belonged to a relative of Bynum\\\\xa0\\\\xa0 Police tracked Vicosas location to Bynums home on Monday and were denied the opportunity to search her residence Baltimore County Police Chief Melissa Hyatt begged Bynum to return the girls to safety at a press conference on Thursday York Area Regional Police Lt Ken Schollenberger had previously pleaded Vicosa to bring the girls home at a conference on Wednesday morning Vicosa then allegedly stole another vehicle on Tuesday after he crashed the Acura into a canal He and the two children then spent a night in a vacant camper\\\\xa0 The female owner of the camper had come to the property the next day where she was held at gunpoint by Vicosa\\\\xa0\\\\xa0 He took the keys to her silver Volkswagen Jetta as well as her cellphone before heading off with the girls\\\\xa0 Police later tracked the location of the vehicle only to discover it was empty\\\\xa0The woman had both her vehicle and cellphone returned to her after it was found Cops then tracked Vicosa to Bynums home and after obtaining a search warrant they entered the home only to find it empty Bynum and her vehicle were both missing Police say they believe the vehicle to be a black 2013 Lexus G350 with Pennsylvania state license plate number KPK2076\\\\xa0 The two young girls Aaminah and Giana were last seen on Tuesday at 1149am in Windsor\\\\xa0 Both Vicosa and Bynum are being begged to return the two young girls to safety Our priority is the safety and wellbeing of (Vicosas daughters) Giana and Aaminah Please get these two innocent and precious children to a safe location Baltimore County Police Chief Melissa Hyatt said at a press conference\\\\xa0 We want to work with you on a safe and peaceful resolution The girls mother had also previously written a statement of her own which was read at a conference on Wednesday\\\\xa0 \\\\xa0I am anxiously awaiting their return the letter had read I miss them and love them and need them home\\\\xa0\\\\xa0 An Amber Alert has not yet been issued for the girls because officers need to have a clear idea of what car Vicosa is driving\\\\xa0 We were seconds away from issuing an Amber Alert Schollenberger said Unfortunately we found the car that he was in and he was not located in it\\\\xa0 At this point the Amber Alert typically attaches to a vehicle or registration plate We dont have a vehicle or registration plate now because the last one that he was in he abandoned\\\\xa0\\\\xa0 The girls have been featured on a missing and endangered persons alert by state police with the kidnapping date listed as Sunday Aaminah has been described as being three feet and eight inches 50 pounds with green eyes and brown hair Giana is four feet and three inches 60 pounds with both brown eyes and hair Were going to use anything to our availability regardless of what his job is to bring this to a safe resolution York Area Regional Police Lt Ken Schollenberger told  a class=class href=https:baltimorecbslocalcom20211117robert-vicosa-tia-bynum-pennsylvania-kidnapping-baltimore-county-police rel=nofollow noreferrer noopener style=font-weight: bold; target=_blankCBS 21a \\\\xa0 Of course if he does have some specialized training were looking to make sure we can counter that by any means necessary\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa0 Published by Associated Newspapers Ltd Part of the Daily Mail The Mail on Sunday & Metro Media Group'"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f6anWkAW07W"
      },
      "source": [
        "## Extend the metadata with new features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQa-kkincda7"
      },
      "source": [
        "From the list of URLs, we can develop more features and output a data table of:    \n",
        "* The URL\n",
        "* The title of the article\n",
        "* 'bag of words' which is the text in the article. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bRDAryGSAaH"
      },
      "source": [
        "bag_of_words = []\n",
        "for url in URLs:\n",
        "  bag_of_words.append(Get_Text_From_Page(url))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hWDNSmYAcC0"
      },
      "source": [
        "titles = []\n",
        "for url in URLs:\n",
        "  titles.append(Get_Soup(url).find(\"title\").contents[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEu3r3tsxeJB"
      },
      "source": [
        "output = pd.DataFrame({\"URLS\":URLs,\"Bag Of Words\":bag_of_words,\"Title\":titles}).drop_duplicates()\n",
        "output.to_csv(SCRAPE_OUTPUT_FILE)\n",
        "execution_time = time.time() - start_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itKGf1hX7fUA"
      },
      "source": [
        "## Output Profiling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rB2ZwFWc6Q6"
      },
      "source": [
        "The data table has been written to the output file. We can close the pipeline by providing some descriptive information about the corpus. The following is a preview of the data's first three rows. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_LYa4QZdXRs"
      },
      "source": [
        "output.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcfHQbLmfbyS"
      },
      "source": [
        "Exploratory data analysis will be conducted on the corpus in the subsequent pipeline which performs NLP analysis. This pipeline is only responsible for extracting the text from the web pages. However, to ensure quaity data is sent to the next pipeline, we can explore:     \n",
        "* The number of articles extracted\n",
        "* Execution time\n",
        "* Check for rows missing text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMsvqEvTeVkv"
      },
      "source": [
        "The total number of articles extracted:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VchTU15I_9Hc"
      },
      "source": [
        "len(output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thDXzgFFeg9S"
      },
      "source": [
        "The time taken to process this many articles (in seconds):     "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK6KYkGc0FBX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "849425ea-82bc-404c-d490-ba7c783eab6c"
      },
      "source": [
        "execution_time "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156.2861065864563"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6NWyuNog3hn"
      },
      "source": [
        "Low word counts indicate a problem extracting text from HTML. We can check how many records have a small word count as follows. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m1ydElvhLw8"
      },
      "source": [
        "ind = output[\"bag_of_words\"].str.len() < 100\n",
        "len(output[ind])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}